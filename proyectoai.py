# -*- coding: utf-8 -*-
"""ProyectoAI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gXJho3gxNnptzz6ZsYdmDdATA4J3OsvW
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np 
import random as rd
import pandas as pd 
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2
from PIL import Image
import os
import keras.backend as K
K.clear_session()

ruta="/content/drive/My Drive/dataset para IA/"
data=[]
labels=[]

height = 30
width = 30
channels = 3
classes = 15#[0,1,2,3,4,5,6,7]
n_classes=classes#len(classes)
n_inputs = height * width*channels

for i in range(classes) :
    path = ruta+"Train/{0}/".format(i)
    print(path)
    Class=os.listdir(path)
    for a in Class:
        try:
            image=cv2.imread(path+a)
            #image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image_from_array = Image.fromarray(image, 'RGB')
            size_image = image_from_array.resize((height, width))
            data.append(np.array(size_image))
            labels.append(i)
        except AttributeError:
            print("ERROR en "+path+a)
Cells=np.array(data)
labels=np.array(labels)

#Randomize the order of the input images
s=np.arange(Cells.shape[0])
np.random.seed(n_classes)
np.random.shuffle(s)
Cells=Cells[s]
labels=labels[s]

#Spliting the images into train and validation sets
(X_train,X_val)=Cells[(int)(0.2*len(labels)):],Cells[:(int)(0.2*len(labels))]
X_train = X_train.astype('float32')/255 
X_val = X_val.astype('float32')/255
(y_train,y_val)=labels[(int)(0.2*len(labels)):],labels[:(int)(0.2*len(labels))]

#Using one hote encoding for the train and validation labels
from keras.utils import to_categorical
y_train = to_categorical(y_train, n_classes)
y_val = to_categorical(y_val, n_classes)

print(len(y_train))
len(y_val)

#take class weight into account
classTotals = y_train.sum(axis = 0)
classWeight = classTotals.max()/classTotals

data_gen_args = dict(
    #featurewise_center=True,
    #featurewise_std_normalization=True,
    #rotation_range=20,
    #width_shift_range=0.15,
    #height_shift_range=0.15,
    rotation_range = 10,
    zoom_range = 0.15,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    shear_range = 0.15,
    horizontal_flip = False,
    vertical_flip = False,
    fill_mode = "nearest"
    )
datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)
#val_datagen = tf.keras.preprocessing.image.ImageDataGenerator()

datagen.fit(X_train)
#val_datagen.fit(X_val)

#Definition of the DNN model
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout

model = Sequential()

model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))
model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(rate=0.25))

model.add(Conv2D(filters=64, kernel_size=(3, 3),activation='relu'))
model.add(Conv2D(filters=64, kernel_size=(3, 3),activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(rate=0.25))

model.add(Flatten())
model.add(Dense(256,activation='relu'))
model.add(Dropout(rate=0.5))
model.add(Dense(n_classes, activation='softmax'))


#Compilation of the model
model.compile(
    loss='categorical_crossentropy', 
    optimizer='adam', 
    metrics=['accuracy']
)

model.summary()

#using 12 epochs for the training and saving the accuracy for each epoch
#with session.as_default():
#  with session.graph.as_default():
epochs = 12
batch_size=11
history=model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),
                            steps_per_epoch=X_train.shape[0]//batch_size, 
                            epochs=epochs, 
                            validation_data=(X_val,y_val),
                            class_weight = classWeight,
                            verbose = 1)
#history = model.fit(X_train, 
#                    y_train, 
#                    batch_size=32, epochs=epochs, 
#                    validation_data=(X_val, y_val))

#Display of the accuracy and the loss values
import matplotlib.pyplot as plt

plt.figure(0)
plt.plot(history.history['acc'], label='training accuracy')
plt.plot(history.history['val_acc'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()

plt.figure(1)
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()

del model

print(history.history.keys())

#Save de Model
model.save(ruta+'model-pro-v6DEFINITIVO.h5')

# Recreate the exact same model, including its weights and the optimizer
model = tf.keras.models.load_model(ruta+'model-pro-v5.h5')

# Show the model architecture
model.summary()

#Reading the test file
y_test=pd.read_csv(ruta+"Test.csv")
img_path=y_test['Path'].as_matrix()
y_test=y_test['ClassId'].values

#Predicting with the test data
data=[]

for f in img_path:
    image=cv2.imread(ruta+f)
    image_from_array = Image.fromarray(image, 'RGB')
    size_image = image_from_array.resize((height, width))
    data.append(np.array(size_image))

X_test=np.array(data)
X_test = X_test.astype('float32')/255 
pred = model.predict_classes(X_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
a=accuracy_score(y_test, pred)
c=classification_report(y_test, pred)
print("accuracy:", a)
print(c)

#Reading the labels file
arch=pd.read_csv(ruta+'labels_ecuador.csv')
arch=arch["SignName"].values

#Picking range of images to test and show them with class
vals=[]
lim=100
offset=20

for f in img_path[lim:lim+offset]:
  data=[]
  img=cv2.imread(ruta+f)
  image_from_array = Image.fromarray(img, 'RGB')
  size_image = image_from_array.resize((height, width))
  data.append(np.array(size_image))
  X_test=np.array(data)
  X_test = X_test.astype('float32')/255 
  pred = model.predict_classes(X_test)
  vals.append(pred)
  plt.imshow(img)
  plt.title(arch[pred[0]])
  plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
a=accuracy_score(y_test[lim:lim+offset], vals)
c=classification_report(y_test[lim:lim+offset], vals)
print(a)
print(c)

#Predicting using images from different sources
pruebas=pd.read_csv(ruta+'MisPruebas.csv')
pathss=pruebas['Path'].values
classs=pruebas['ClassId'].values
vals=[]
for a in pathss:
  data=[]
  img=cv2.imread(ruta+a)
  #img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

  try:
    image_from_array = Image.fromarray(img, 'RGB')
    size_image = image_from_array.resize((height, width))
    data.append(np.array(size_image))
    X_test=np.array(data)
    X_test = X_test.astype('float32')/255 
    pred = model.predict_classes(X_test)
    vals.append(pred)
    plt.imshow(img)
    plt.title(arch[pred[0]])
    plt.show()
  except AttributeError:
    print("ERROR en "+path+a)

from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
a=accuracy_score(classs, vals)
c=classification_report(classs, vals)
print(a)
print(c)

import tensorflow as tf
ruta="/content/drive/My Drive/dataset para IA/"
file="model-pro-v2.h5"

converter = tf.lite.TFLiteConverter.from_keras_model_file(ruta+file)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_quant_model = converter.convert()
open(ruta+"converted_model_optv2.tflite", "wb").write(tflite_quant_model)

converter = tf.lite.TFLiteConverter.from_keras_model_file(ruta+file)
tflite_quant_model = converter.convert()
open(ruta+"converted_modelv2.tflite", "wb").write(tflite_quant_model)